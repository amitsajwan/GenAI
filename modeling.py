def perform_modeling(
    modeling_script_filename,
    modeling_report_filename,
    x_train_path,
    y_train_path,
    x_val_path,
    y_val_path,
    x_test_path,
    y_test_path,
    model_output_path,
    scaler_path,
    preliminary_analysis_report_content,
    eda_result_summary,
    feature_engineering_report,
    date_index_name
):
    modeling_prompt = f"""
**YOU ARE THE AI PROMPT CREATOR FOR PYTHON MODELING SCRIPT GENERATION**

**Your Mission:**
Your primary responsibility is to act as an intelligent decision-maker and prompt engineer. You will receive summaries from upstream data analysis processes (Preliminary Analysis, EDA, Feature Engineering) and various configuration parameters (file paths, names). Based on a thorough analysis of these inputs, you must dynamically construct a highly detailed, explicit, and self-contained "Execution Prompt." This "Execution Prompt" is your *sole output*. It will be passed directly to a non-reasoning `pythonTool`, which will use it to generate a Python script for building, training, evaluating, and saving a stock price prediction model. The Python script generated by the `pythonTool` must prioritize robustness, effective generalization, and address common machine learning challenges like overfitting based on the guidance in the "Execution Prompt" you create.

**Inputs You Have Received (from the system calling you):**

1.  **`eda_result_summary_content`**: "{eda_result_summary}"
2.  **`feature_engineering_report_content`**: "{feature_engineering_report}"
3.  **`preliminary_analysis_report_for_context`**: "{preliminary_analysis_report_content}"
4.  **`x_train_path_for_script`**: "{x_train_path}"
5.  **`y_train_path_for_script`**: "{y_train_path}"
6.  **`x_val_path_for_script`**: "{x_val_path}"
7.  **`y_val_path_for_script`**: "{y_val_path}"
8.  **`x_test_path_for_script`**: "{x_test_path}"
9.  **`y_test_path_for_script`**: "{y_test_path}"
10. **`model_output_path_for_script`**: "{model_output_path}"
11. **`scaler_path_for_script`**: "{scaler_path}"
12. **`target_modeling_script_filename`**: "{modeling_script_filename}"
13. **`target_modeling_report_filename`**: "{modeling_report_filename}"
14. **`target_date_index_name_for_script`**: "{date_index_name if date_index_name else 'None'}"

**Your Decision-Making and Reasoning Process (Follow these steps to determine content for the "Execution Prompt" you will generate):**

**Phase 1: Analyze Input Summaries**
* Scrutinize `eda_result_summary_content` (provided as: "{eda_result_summary}"):
    * Outlier Assessment: Identify features with significant outliers. Decide on a specific handling strategy (e.g., winsorize specific columns, instruct `pythonTool` to use RobustScaler).
    * Skewness Assessment: Identify highly skewed features. Decide on a transformation strategy (e.g., instruct `pythonTool` to apply np.log1p before scaling).
* Scrutinize `feature_engineering_report_content` (provided as: "{feature_engineering_report}"):
    * Model Suitability Hints: Look for suggestions for model families.
    * Feature Importance/Interactions: Note findings that might influence model choice.
* Briefly review `preliminary_analysis_report_for_context` (provided as: "{preliminary_analysis_report_content}") for any overarching context that might influence modeling choices (e.g., specific constraints, evaluation priorities).

**Phase 2: Formulate the Modeling Strategy**
* A. Define Specific Preprocessing Augmentations for `pythonTool`: Based on Phase 1, formulate concise instructions for the `pythonTool` regarding outlier handling and transformations. Specify target column names if applicable.
* B. Select the Primary Model for `pythonTool`: Choose ONE primary regression model (e.g., RandomForestRegressor, GradientBoostingRegressor, XGBoostRegressor). Justify this choice briefly based on Phase 1.
* C. Design the Hyperparameter Tuning Plan for `pythonTool`: Mandate `GridSearchCV` (or `RandomizedSearchCV`) with cv>=3. Identify 3-5 key hyperparameters for the chosen model and define a specific Python dictionary string for the search grid. The scoring metric for tuning should be 'neg_root_mean_squared_error' or 'r2'.

**Phase 3: Construct Your Output â€“ The "Execution Prompt" for `pythonTool`**
* Your final output MUST be a single string. This string is the "Execution Prompt".
* This "Execution Prompt" string that you generate MUST be a valid Python f-string (it must start with `f\"\"\"` and end with `\"\"\"`).
* Use the **"STRUCTURE FOR EXECUTION PROMPT"** described below as a guide for the content and layout of the f-string you generate.
* Dynamically populate the instructional placeholders (e.g., `[Your reasoned model import...]`, `[Your reasoned outlier/transformation instructions...]`) with your decisions from Phase 1 & 2.
* Ensure all path and filename variables (e.g., the value of `target_modeling_script_filename` which is "{modeling_script_filename}", the value of `x_train_path_for_script` which is "{x_train_path}", etc.) are correctly embedded as string literals or f-string components within the "Execution Prompt" string you are generating for the `pythonTool`.

---
**STRUCTURE FOR EXECUTION PROMPT (This describes the f-string you, the Prompt Creator LLM, will construct and output. Your output f-string must use the actual values for paths and filenames provided in the 'Inputs You Have Received' section above.)**
---

**Your output f-string should look like this example (replace bracketed parts with your reasoned decisions and use the actual path/filename values):**

`f\"\"\"`
`# Start of the Execution Prompt string generated by the Prompt Creator LLM.`
`# All paths and filenames below are the actual string values.`

`**Goal:** Generate an executable Python script ('{target_modeling_script_filename}') to build, train, evaluate, and save a machine learning regression model for stock price prediction. The script must follow all instructions precisely.`

`**Overall Objective:** Build and train a machine learning model using data from '{x_train_path_for_script}', '{y_train_path_for_script}', '{x_val_path_for_script}', '{y_val_path_for_script}', '{x_test_path_for_script}', and '{y_test_path_for_script}'.`

`**Mandatory Rules for Python code generation:**`
`# (List the rules: no script arguments, do not suppress exceptions, use joblib for model I/O)`

`**Suggested Python Script Imports (for the '{target_modeling_script_filename}'):**`
`import pandas as pd`
`import numpy as np`
`import joblib`
`from sklearn.model_selection import GridSearchCV # Or RandomizedSearchCV, as you decided`
`from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score`
`# [Prompt Creator: Insert model import based on your Phase 2B decision. E.g., from sklearn.ensemble import RandomForestRegressor]`
`# [Prompt Creator: Insert relevant scaler imports based on your Phase 2A decision and the primary scaler. E.g., from sklearn.preprocessing import StandardScaler, RobustScaler]`
`# [Prompt Creator: If winsorizing decided as part of Phase 2A strategy: from scipy.stats.mstats import winsorize]`

`**Python Script Fixed Inputs (Define these at the top of '{target_modeling_script_filename}'):**`
`x_train_path_script = '{x_train_path_for_script}'`
`y_train_path_script = '{y_train_path_for_script}'`
`x_val_path_script = '{x_val_path_for_script}'`
`y_val_path_script = '{y_val_path_for_script}'`
`x_test_path_script = '{x_test_path_for_script}'`
`y_test_path_script = '{y_test_path_for_script}'`
`model_output_path_script = '{model_output_path_for_script}'`
`scaler_path_script = '{scaler_path_for_script}'`
`date_index_name_script = '{target_date_index_name_for_script}'`

`**Python Script Operational Instructions (for '{target_modeling_script_filename}'):**`

`    # Subsection: 1. Load Data Function`
`    # (Define function load_data(features_path, target_path, index_col_name): reads CSVs, sets index if valid (parse as datetime), ensures y is 1D pandas Series. Returns X, y. Call for train, val, test.)`

`    # Subsection: 2. Preprocess Data Function`
`    # (Define function preprocess_data(X_train_df, X_val_df, X_test_df, primary_scaler_path): Copy DataFrames. [Your reasoned transformation instructions from Phase 2A for operations BEFORE primary scaling, specifying columns]. Load primary scaler. Apply scaler (handle DataFrame reconstruction if scaler outputs numpy). [Your reasoned outlier handling instructions from Phase 2A for operations AFTER primary scaling, specifying columns]. Returns X_train_processed, X_val_processed, X_test_processed. Call function.)`

`    # Subsection: 3. Model Training and Hyperparameter Tuning Function`
`    # (Define function train_and_tune_model(X_train_processed, y_train_raw): [Your chosen model instantiation from Phase 2B, e.g., model = RandomForestRegressor(random_state=42)]. [Your chosen hyperparameter grid as a Python dictionary string from Phase 2C, e.g., param_grid = {{ 'n_estimators': [50,100], ... }}]. Instantiate GridSearchCV (cv, scoring, n_jobs, verbose=1). Ensure y_train_raw is 1D for fit. Fit GridSearchCV. Extract best_estimator_ as final_model. Print best_params_. Returns final_model, best_params_. Call function.)`

`    # Subsection: 4. Model Evaluation Function`
`    # (Define function evaluate_model(model, X_data, y_data, dataset_name): Ensure y_data is 1D. Predict. Calculate MAE, MSE, RMSE, R2. Print metrics. Returns metrics dict. Call for train, val, test sets.)`

`    # Subsection: 5. Save Model Function`
`    # (Define function save_model_artifact(model, path): joblib.dump(model, path). Print save message. Call to save final_model to model_output_path_script.)`

`    # Subsection: 6. Prepare and Save Evaluation Report Function`
`    # (Define function generate_report(report_path, chosen_model_name_str, best_params_dict, train_metrics_dict, val_metrics_dict, test_metrics_dict): Write to report_path: chosen_model_name_str [from Phase 2B], str(best_params_dict), formatted metrics. Include placeholder text for Observations/Insights. Print save message. Call function.)`

`    # Subsection: 7. Main Script Execution Flow`
`    # (Wrap calls in if __name__ == '__main__': block: Load data, Preprocess, Train/Tune, Evaluate, Save Model, Generate Report. Print final success message.)`
`\"\"\"`
`# End of the Execution Prompt string to be generated by the Prompt Creator LLM.`

"""
    return modeling_prompt
                                          
