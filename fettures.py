# Inside your perform_feature_engineering function:
# fe_script_filename, fe_report_filename, cleaned_train_path, ... , y_test_path, index_name
# are arguments to your function.

# Specific configuration values based on your input:
target_variable_name_value = "Close"
feature_transformer_output_path_value = "models/fe_transformers.pkl"
ohlcv_columns_value = "Open,High,Low,Close,Volume"
other_date_columns_value = "idx" # As 'idx' is your date column

# Now, construct the prompt using these values and your function arguments
fe_prompt_for_creator_llm = f"""
**YOU ARE THE AI PROMPT CREATOR FOR PYTHON FEATURE ENGINEERING SCRIPT GENERATION**

**Your Mission:**
Your primary responsibility is to analyze the provided data summaries and configuration details. Based on this analysis, you will make strategic decisions for feature engineering. Your *sole output* will be a highly detailed and explicit "Execution Prompt" designed for a non-reasoning `pythonTool`. This `pythonTool` will use your "Execution Prompt" to generate a Python script that performs the feature engineering tasks you've outlined, preparing data for modeling.

**SECTION 1: CONTEXT AND DATA (Values embedded from your Python function's arguments and configurations)**

1.  **EDA Report Summary:**
    ```
    {eda_result_summary}
    ```
2.  **Preliminary Analysis Report Context:**
    ```
    {preliminary_analysis_report_content}
    ```
3.  **Input Data Paths (Cleaned X Features - FE process will also need corresponding y input):**
    * Training Features (X_train_cleaned): `{cleaned_train_path}`
    * Validation Features (X_val_cleaned): `{cleaned_val_path if cleaned_val_path else 'None'}`
    * Test Features (X_test_cleaned): `{cleaned_test_path if cleaned_test_path else 'None'}`
    *(LLM Note: The Python script generated by the `pythonTool` will need to load corresponding y data for these X inputs. The target variable name "{target_variable_name_value}" is crucial for identifying and separating `y` if it's part of these input files, or for loading separate y files if their paths are implicitly related to these X paths.)*

4.  **Output Data Paths & Artifacts (Targets for the `pythonTool` script, provided by the calling Python function):**
    * Feature-Engineered Training Features (X_train_fe): `{x_train_path}`
    * Aligned Training Target (y_train_fe): `{y_train_path}`
    * Feature-Engineered Validation Features (X_val_fe): `{x_val_path}`
    * Aligned Validation Target (y_val_fe): `{y_val_path}`
    * Feature-Engineered Test Features (X_test_fe): `{x_test_path}`
    * Aligned Test Target (y_test_fe): `{y_test_path}`
    * Fitted Feature Transformers: `{feature_transformer_output_path_value}`

5.  **Key Column Names & Configuration:**
    * Target Variable Name: `{target_variable_name_value}`
    * Index Column Name (from function argument, also your date column): `{index_name}` 
    * OHLCV Columns (comma-separated, or 'None'): `{ohlcv_columns_value}`
    * Other Date Columns (comma-separated, or 'None'): `{other_date_columns_value}` 
      *(LLM Note: Since 'idx' is specified as the date column and is also the index_name, ensure date feature extraction targets this column correctly, whether it's initially a column or already set as index.)*

6.  **Target Script and Report Names (for the `pythonTool` script):**
    * Feature Engineering Script Filename: `{fe_script_filename}`
    * Feature Engineering Report Filename: `{fe_report_filename}`

**SECTION 2: YOUR STRATEGIC DECISION-MAKING FOR FEATURE ENGINEERING**
(Based on the inputs in Section 1, particularly `eda_result_summary` and `preliminary_analysis_report_content`, determine the feature engineering strategy. Your decisions here will guide the structure and content of the "Execution Prompt" you generate for the `pythonTool`.)

1.  **Column Identification and Grouping:**
    * Based on EDA, `{ohlcv_columns_value}`, and `{other_date_columns_value}`, identify numerical, categorical, and date columns present in the input data (e.g., from `{cleaned_train_path}`). Note the target variable is "{target_variable_name_value}" and the index/date column is "{index_name}".
2.  **Initial Imputation (Full DataFrame, if necessary, especially if target is used for FE):**
    * Is an initial imputation needed on data loaded from `{cleaned_train_path}` (which might include "{target_variable_name_value}" initially, like "Close" from OHLCV) before further processing or X/y split? What strategy (e.g., forward-fill for time series like "Close")?
3.  **Target Variable Handling:**
    * If "{target_variable_name_value}" is present in the DataFrames loaded from `{cleaned_train_path}` (etc.), decide when it should be separated into `y_train`, `y_val`, `y_test`. This is usually after all features that might depend on it (like "Close" for creating returns or MAs) are generated, but before applying transformations only to X.
4.  **Domain-Specific Feature/Signal Generation (e.g., Market Signals):**
    * Based on `preliminary_analysis_report_content`, EDA, and the OHLCV columns ("{ohlcv_columns_value}"), what new features or signals should be created? List types and key parameters (lags, windows for MAs, volatility from OHLCV, returns from "Close", etc.).
5.  **Date/Time Feature Creation:**
    * From the primary date column "{index_name}" (which you've identified as "{other_date_columns_value}"), what date/time components should be extracted (Year, Month, DayOfWeek, IsWeekend, Quarter, etc.)?
6.  **Interaction/Polynomial Feature Creation (Optional):**
    * Does EDA suggest any useful interaction terms or polynomial features?
7.  **Post-Feature Creation NaN Handling (Mainly for X, but align y):**
    * After creating new features, how should introduced NaNs be handled (e.g., drop rows from X and correspondingly from y; or specific imputation for X)? Prioritize chronological alignment and document the strategy.
8.  **Final Imputation (X features only, after target separation):**
    * What imputation strategy for remaining NaNs in numerical X features?
    * What imputation strategy for categorical X features?
9.  **Feature Scaling (Numerical X features):**
    * What scaling technique for numerical X features?
10. **Categorical Encoding (Categorical X features):**
    * What encoding scheme for categorical X features?
11. **Feature Dropping (Optional):**
    * Any columns to be dropped from X after they've served their purpose?
12. **Order of Operations:**
    * Outline the logical sequence of these FE steps.

**SECTION 3: CONSTRUCT YOUR OUTPUT â€“ THE "EXECUTION PROMPT" FOR `pythonTool`**
(Your *sole output* for this current task is a single string: the "Execution Prompt." This "Execution Prompt" must be a valid Python f-string (it must start with `f\"\"\"` and end with `\"\"\"`). It will instruct the `pythonTool` to generate a Python script that implements the feature engineering strategy you formulated in Section 2.)

**Key requirements for the "Execution Prompt" you generate:**

1.  **Clarity and Detail:** Provide unambiguous instructions for the `pythonTool`.
2.  **Structure:** Guide `pythonTool` to create a script with functions for major FE steps.
3.  **Fit/Transform Paradigm:** Transformers (`fit` ONLY on training data, then `transform` train, val, test).
4.  **Saving Artifacts:** Instruct `pythonTool`'s script to save:
    * Transformed X DataFrames to paths like `{x_train_path}`.
    * Aligned y DataFrames to paths like `{y_train_path}`.
    * All *fitted* transformers to `{feature_transformer_output_path_value}`.
    * A report to `{fe_report_filename}`.
5.  **Variable Usage:** The "Execution Prompt" you generate must correctly embed the *actual string values* for all paths and filenames (e.g., "{cleaned_train_path}", "{x_train_path}", "{fe_script_filename}", "{target_variable_name_value}") into its instructions for the `pythonTool`.
6.  **Pythonic Code:** Guide towards clean Python.

**Example of how you (Prompt Creator LLM) might instruct the `pythonTool` for date feature extraction within the Execution Prompt:**
"...The Execution Prompt should instruct `pythonTool` for 'Date/Time Feature Creation':
`# --- Date/Time Feature Creation ---`
`# The primary date column is '{index_name}'. Ensure it is in datetime format.`
`# For each DataFrame (df_train_fe, df_val_fe, df_test_fe):`
`#   date_col_series = df_current.index if isinstance(df_current.index, pd.DatetimeIndex) else pd.to_datetime(df_current['{index_name}'])`
`#   df_current['year'] = date_col_series.dt.year`
`#   df_current['month'] = date_col_series.dt.month`
`#   df_current['dayofweek'] = date_col_series.dt.dayofweek`
`#   df_current['dayofyear'] = date_col_series.dt.dayofyear`
`#   df_current['weekofyear'] = date_col_series.isocalendar().week.astype(int)`
`# If '{index_name}' was a regular column and not the index, consider dropping it after extraction.`
"
"""
    # This fe_prompt_for_creator_llm is now fully populated with both
    # your function arguments and the specific config values you provided.
    # It's ready to be sent to your "Prompt Creator" LLM.
    #
    # llm_output_execution_prompt = call_your_llm(fe_prompt_for_creator_llm)
    # return llm_output_execution_prompt
